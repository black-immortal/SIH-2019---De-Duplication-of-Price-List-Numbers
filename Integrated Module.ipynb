{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############################# DEMO ####################\n",
    "\n",
    "data = np.array([[12345678,'ABC'],[23456789,'DEF'],[34567890,'GHI'],[45678901,'JKL'],[56789012, 'MNO'],\n",
    "                 [12345678,'BOO'],[12341008,'CDD'],[23456789,'DEF'],[23456789,'XCD'],[23456789,'IOP']\n",
    "                 ,[23456789,'IOP'],[23456789,'IOP'],[23456789,'IOP'],[23456789,'IOP'],[23456789,'IOP']\n",
    "                 ,[23456789,'IOP'],[23456789,'IOP'],[23456789,'IOP'],[23456789,'IOP'],[23456789,'IOP']\n",
    "                 ,[23456789,'IOP'],[23456789,'IOP'],[23456789,'IOP'],[23456789,'IOP'],[23456789,'IOP']\n",
    "                 ,[23456789,'IOP'],[23456789,'IOP'],[23456789,'IOP'],[23456789,'IOP'],[23456789,'IOP']\n",
    "                ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################### IMPORT LIBRARIES ################\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### EXTRACT DATA ###########\n",
    "df_dataset = pd.read_excel('1-converted.xlsx')\n",
    "df_plbook = pd.read_excel('pl_numbers.xlsx')\n",
    "sheet = df_dataset.values\n",
    "data = sheet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Part I\n",
    "\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from spellchecker import SpellChecker\n",
    "# import enchant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def removeAbbreviations(statement):\n",
    "    \n",
    "    abbr = dict()\n",
    "\n",
    "    abbr[\"ft\"] = \"foot\"\n",
    "    abbr[\"mm\"] = \"millimeter\"\n",
    "    abbr[\"cm\"] = \"centimeter\"\n",
    "    abbr[\"m\"] = \"meter\"\n",
    "    abbr[\"km\"] = \"kilometer\"\n",
    "    abbr[\"yd\"] = \"yard\"\n",
    "    abbr[\"mi\"] = \"mile\"\n",
    "    abbr[\"lb\"] = \"pound\"\n",
    "    abbr[\"oz\"] = \"ounce\"\n",
    "    abbr[\"mg\"] = \"milligram\"\n",
    "    abbr[\"g\"] = \"gram\"\n",
    "    abbr[\"kg\"] = \"kilogram\"\n",
    "    abbr[\"ml\"] = \"milliliter\"\n",
    "    abbr[\"l\"] = \"liter\"\n",
    "    abbr[\"mph\"] = \"miles per hour\"\n",
    "    abbr[\"kmph\"] = \"kilometers per hour\"\n",
    "    abbr[\"cu\"] = \"cubic\"\n",
    "    abbr[\"rpm\"] = \"revolutions per minute\"\n",
    "    abbr[\"&\"] = \"and\"\n",
    "    abbr[\"$\"] = \"dollar\"\n",
    "    abbr[\"Â°\"] = \"degree\"\n",
    "    abbr['\"'] = \"inch\"\n",
    "    \n",
    "    statement_ = \"\"\n",
    "    \n",
    "    for word in statement.split():\n",
    "        if word in abbr:\n",
    "            statement_ = statement_ + \" \" + abbr[word]\n",
    "        else:\n",
    "            statement_ = statement_ + \" \" + word\n",
    "            \n",
    "    return statement_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def spelling(spellCheck, tokens1, tokens2):\n",
    "    \n",
    "    spell = SpellChecker()\n",
    "    misspelled = spell.unknown(spellCheck)\n",
    "\n",
    "    spellCheck_ = []\n",
    "    for i in misspelled:\n",
    "        spellCheck_.append(i)\n",
    "\n",
    "    for i in range(len(spellCheck_)):\n",
    "        spellCheck_[i] = spell.correction(spellCheck_[i])\n",
    "    \n",
    "    for word in spellCheck_:\n",
    "        if not wordnet.synsets(word):\n",
    "            spellCheck_.remove(word)\n",
    "        \n",
    "    for word in spellCheck_:\n",
    "        flag1 = True\n",
    "        flag2 = True\n",
    "        for i in tokens1:\n",
    "            if word == i:\n",
    "                flag1 = False\n",
    "                break\n",
    "        for i in tokens2:\n",
    "            if word == i:\n",
    "                flag2 = False\n",
    "                break\n",
    "        if flag1 == True and flag2 == True:\n",
    "            spellCheck_.remove(word)\n",
    "    \n",
    "    return spellCheck_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkSimilar(list1, list2):\n",
    "    list1_copy = []\n",
    "    for i in list1:\n",
    "        list1_copy.append(i)\n",
    "    list2_copy = []\n",
    "    for i in list2:\n",
    "        list2_copy.append(i)\n",
    "    \n",
    "    dict1 = dict()\n",
    "    for i in list1:\n",
    "        dict1[i] = 0\n",
    "    for i in list2:\n",
    "        dict1[i] = 0\n",
    "    for i in list1:\n",
    "        dict1[i] = 1 + dict1[i]\n",
    "        \n",
    "    dict2 = dict()\n",
    "    for i in list1:\n",
    "        dict2[i] = 0\n",
    "    for i in list2:\n",
    "        dict2[i] = 0\n",
    "    for i in list2:\n",
    "        dict2[i] = 1 + dict2[i]\n",
    "        \n",
    "    flag = True    \n",
    "    for i in list1:\n",
    "        if dict1[i] != dict2[i]:\n",
    "            flag = False\n",
    "            break\n",
    "            \n",
    "    return flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkSimilarity(S1, S2):\n",
    "    \n",
    "    S1 = S1.lower()\n",
    "    S2 = S2.lower()\n",
    "    \n",
    "    S1 = removeAbbreviations(S1)\n",
    "    S2 = removeAbbreviations(S2)\n",
    "    \n",
    "    S1 = S1[1:len(S1)]\n",
    "    S2 = S2[1:len(S2)]\n",
    "    \n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    words1 = tokenizer.tokenize(S1)\n",
    "    words2 = tokenizer.tokenize(S2)\n",
    "        \n",
    "    spellCheck = []\n",
    "    for i in words1:\n",
    "        flag = True\n",
    "        for j in words2:\n",
    "            if i == j:\n",
    "                flag = False\n",
    "                break\n",
    "        if flag == True:\n",
    "            spellCheck.append(i)\n",
    "    for i in words2:\n",
    "        flag = True\n",
    "        for j in words1:\n",
    "            if i == j:\n",
    "                flag = False\n",
    "                break\n",
    "        if flag == True:\n",
    "            spellCheck.append(i)\n",
    "        \n",
    "    corrected_spellings = spelling(spellCheck, words1, words2)\n",
    "    \n",
    "    for i in corrected_spellings:\n",
    "        if i in spellCheck:\n",
    "            spellCheck.remove(i)\n",
    "    \n",
    "    for i in range(len(corrected_spellings)):\n",
    "        for j in range(len(words1)):\n",
    "            if words1[j] == spellCheck[i]:\n",
    "                words1[j] = corrected_spellings[i]\n",
    "        for j in range(len(words2)):\n",
    "            if words2[j] == spellCheck[i]:\n",
    "                words2[j] = corrected_spellings[i]\n",
    "\n",
    "    porter = PorterStemmer()\n",
    "\n",
    "    lemmatize1 = []\n",
    "    lemmatize2 = []\n",
    "\n",
    "    for word in words1:\n",
    "        lemmatize1.append(porter.stem(word))\n",
    "    for word in words2:\n",
    "        lemmatize2.append(porter.stem(word))\n",
    "        \n",
    "    for i in range(len(lemmatize1)):\n",
    "        words1[i] = lemmatize1[i]\n",
    "    for i in range(len(lemmatize2)):\n",
    "        words2 = lemmatize2\n",
    "    \n",
    "    tokens1 = []\n",
    "    for i in words1:\n",
    "        tokens1.append(i)\n",
    "    tokens2 = []\n",
    "    for i in words2:\n",
    "        tokens2.append(i)\n",
    "    \n",
    "    d = enchant.Dict(\"en_US\")\n",
    "    for word in words1:\n",
    "        if d.check(word) == False:\n",
    "            words1.remove(word)\n",
    "    for word in words2:\n",
    "        if d.check(word) == False:\n",
    "            words2.remove(word)\n",
    "            \n",
    "    technical_terms1 = []\n",
    "    for i in tokens1:\n",
    "        check = False\n",
    "        for j in words1:\n",
    "            if i == j:\n",
    "                check = True\n",
    "                break\n",
    "        if check == False:\n",
    "            technical_terms1.append(i)\n",
    "\n",
    "    technical_terms2 = []\n",
    "    for i in tokens2:\n",
    "        check = False\n",
    "        for j in words2:\n",
    "            if i == j:\n",
    "                check = True\n",
    "                break\n",
    "        if check == False:\n",
    "            technical_terms2.append(i)\n",
    "            \n",
    "    flag = False\n",
    "    flag1 = True\n",
    "\n",
    "    if len(technical_terms1) == len(technical_terms2) and len(technical_terms1) == 0:\n",
    "        None\n",
    "    elif len(technical_terms1) != len(technical_terms2):\n",
    "        flag1 = False\n",
    "    else:\n",
    "        if checkSimilar(technical_terms1, technical_terms2):\n",
    "            flag1 = True     \n",
    "\n",
    "    if flag1 == True:\n",
    "        from nltk.corpus import stopwords\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        stop_words1 = [w for w in words1 if not w in stop_words]\n",
    "        stop_words2 = [w for w in words2 if not w in stop_words]\n",
    "\n",
    "        flag = True\n",
    "        if len(stop_words1) != len(stop_words2):\n",
    "            flag = False\n",
    "        else:\n",
    "            flag = checkSimilar(stop_words1, stop_words2)\n",
    "\n",
    "    return flag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sameDescription(data1, data2):\n",
    "    flag = checkSimilarity(data1,data2)\n",
    "    return flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'enchant' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-c7a0d41cc1c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'True'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mcheck\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msameDescription\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheck\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-e0b79096a5a2>\u001b[0m in \u001b[0;36msameDescription\u001b[1;34m(data1, data2)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msameDescription\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mflag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheckSimilarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-4bd3ac0b8b34>\u001b[0m in \u001b[0;36mcheckSimilarity\u001b[1;34m(S1, S2)\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[0mtokens2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m     \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menchant\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"en_US\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'enchant' is not defined"
     ]
    }
   ],
   "source": [
    "############ Driver function for part 1 gives list ############\n",
    "flag = np.array([False for i in range(data.shape[0])])\n",
    "flag = flag.reshape((data.shape[0],1))\n",
    "data = np.c_[data,flag]\n",
    "n = data.shape[0]\n",
    "uniqueDescriptions = []\n",
    "for i in range(n):\n",
    "    if(data[i][2]=='True'):\n",
    "        continue\n",
    "    data[i][2] = 'True'\n",
    "    row = [data[i][1]]\n",
    "    for j in range(i+1,n):\n",
    "        if(data[j][2]=='True'):\n",
    "            continue\n",
    "        check = sameDescription(data[i][1],data[j][1])\n",
    "        if(check==True):\n",
    "            row.append(data[j][1])\n",
    "            data[j][2]= 'True'\n",
    "    uniqueDescriptions.append(row)\n",
    "    \n",
    "    \n",
    "######################## PART 1 ENDS ########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#################### PART 2 BEGINS ########################\n",
    "\n",
    "data = sheet\n",
    "df = df_plbook\n",
    "df['desc']=df['Description_A(1)']+\" \"+df['Description_A(2)']+\" \"+df['Description_B']# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "\n",
    "\n",
    "lis=df['desc'].tolist()\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "t =\"\"\n",
    "for i in range(data.shape[0]):\n",
    "    t+= str(lis[i])\n",
    "    t+=\" \"\n",
    "doc = nlp(t)\n",
    "\n",
    "\n",
    "\n",
    "def group(d):\n",
    "    m_val = 0\n",
    "    m_index = 0\n",
    "    des_str = nlp(u\"\"+d)\n",
    "\n",
    "    for i in range(308):\n",
    "#     print(i)\n",
    "        db_str = nlp(str(lis[i]))\n",
    "        similarity = des_str.similarity(db_str)\n",
    "#     print(i,db_str,similarity)\n",
    "        if(similarity>m_val):\n",
    "            m_index = i\n",
    "            m_val=similarity\n",
    "#     print(\"max Similarity\",m_val)\n",
    "    a = df.iloc[m_index,1]\n",
    "    b = df.iloc[m_index,2]\n",
    "    print(\"A\",a,\"B\",b)\n",
    "    x=df.iloc[m_index,0];\n",
    "    x=str(\"{:04d}\".format(x))\n",
    "    \n",
    "    return int(x);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############# DRIVER FOR PART 2 ################\n",
    "\n",
    "mapping = {}\n",
    "for element in uniqueDescriptions:\n",
    "    pl = group(element[0])\n",
    "    if pl not in mapping:\n",
    "        mapping[pl] = [element]\n",
    "    else:\n",
    "        mapping[pl].append(element)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################ PART 2 ENDS ####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############### PART 3 BEGINS ##################\n",
    "def calc(A,B,C):\n",
    "    pl = int(A+B+C)\n",
    "    sum =0\n",
    "    i = 2\n",
    "    while(pl!=0):\n",
    "        \n",
    "        rem = pl%10\n",
    "        sum+=rem*i\n",
    "        pl//=10\n",
    "        i+=1\n",
    "    if(sum%11 == 10):\n",
    "        return '0'\n",
    "    return str(sum%11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ChangeHex(n):\n",
    "    if (n<=1):\n",
    "        return (str(n))\n",
    "    else:\n",
    "        ans = ChangeHex( n // 16 )\n",
    "        x =(n%16)\n",
    "        s = str(x)\n",
    "        if (x < 10):\n",
    "            return (ans+s)  \n",
    "        if (x == 10):\n",
    "            return (ans+\"A\")\n",
    "        if (x == 11):\n",
    "            return (ans+\"B\")\n",
    "        if (x == 12):\n",
    "            return (ans+\"C\")\n",
    "        if (x == 13):\n",
    "            return (ans+\"D\")\n",
    "        if (x == 14):\n",
    "            return (ans+\"E\")\n",
    "        if (x == 15):\n",
    "            return (ans+\"F\")\n",
    "        else:\n",
    "            return (5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fix(mapping, pl, descriptions):\n",
    "    \n",
    "    pl = str(pl)\n",
    "    key = 0\n",
    "    if(len(pl)<4):\n",
    "        pl = '0'+pl\n",
    "    A = pl[0:2]\n",
    "    B = pl[2:4]\n",
    "    \n",
    "    for i in range(len(descriptions)):\n",
    "        hex = ChangeHex(key)\n",
    "        if(len(hex)<2):\n",
    "            hex = '00'+hex\n",
    "        elif(len(hex)<3):\n",
    "            hex = '0'+hex\n",
    "            \n",
    "        allotedPl = A+B+hex+D#calc(A,B,key)\n",
    "        mapping[allotedPl] = [dsc]\n",
    "        key+=1\n",
    "    \n",
    "    mapping.pop(pl,None)  \n",
    "    \n",
    "    \n",
    "    return mapping   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############### DRIVER FOR PART 3 ##############\n",
    "pl = sorted(mapping.keys())\n",
    "\n",
    "for num in pl:\n",
    "    val = mapping[num]\n",
    "    if(len(val)>1):\n",
    "        print('\\033[30;1;46m',num,':',mapping[num])\n",
    "    else:    \n",
    "        print('\\033[30;1;m',num,':',mapping[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num in pl:\n",
    "    val = mapping[num]\n",
    "    if(len(val)>1):\n",
    "        mapping = fix(mapping,num,val)\n",
    "        \n",
    "print('\\n\\n\\n###########\\n\\n')\n",
    "for key in mapping:\n",
    "    print(key,':', mapping[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
