{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part I\n",
    "\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from spellchecker import SpellChecker\n",
    "# import enchant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def removeAbbreviations(statement):\n",
    "    \n",
    "    abbr = dict()\n",
    "\n",
    "    abbr[\"ft\"] = \"foot\"\n",
    "    abbr[\"mm\"] = \"millimeter\"\n",
    "    abbr[\"cm\"] = \"centimeter\"\n",
    "    abbr[\"m\"] = \"meter\"\n",
    "    abbr[\"km\"] = \"kilometer\"\n",
    "    abbr[\"yd\"] = \"yard\"\n",
    "    abbr[\"mi\"] = \"mile\"\n",
    "    abbr[\"lb\"] = \"pound\"\n",
    "    abbr[\"oz\"] = \"ounce\"\n",
    "    abbr[\"mg\"] = \"milligram\"\n",
    "    abbr[\"g\"] = \"gram\"\n",
    "    abbr[\"kg\"] = \"kilogram\"\n",
    "    abbr[\"ml\"] = \"milliliter\"\n",
    "    abbr[\"l\"] = \"liter\"\n",
    "    abbr[\"mph\"] = \"miles per hour\"\n",
    "    abbr[\"kmph\"] = \"kilometers per hour\"\n",
    "    abbr[\"cu\"] = \"cubic\"\n",
    "    abbr[\"rpm\"] = \"revolutions per minute\"\n",
    "    abbr[\"&\"] = \"and\"\n",
    "    abbr[\"$\"] = \"dollar\"\n",
    "    abbr[\"Â°\"] = \"degree\"\n",
    "    abbr['\"'] = \"inch\"\n",
    "    \n",
    "    statement_ = \"\"\n",
    "    \n",
    "    for word in statement.split():\n",
    "        if word in abbr:\n",
    "            statement_ = statement_ + \" \" + abbr[word]\n",
    "        else:\n",
    "            statement_ = statement_ + \" \" + word\n",
    "            \n",
    "    return statement_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def spelling(spellCheck, tokens1, tokens2):\n",
    "    \n",
    "    spell = SpellChecker()\n",
    "    misspelled = spell.unknown(spellCheck)\n",
    "\n",
    "    spellCheck_ = []\n",
    "    for i in misspelled:\n",
    "        spellCheck_.append(i)\n",
    "\n",
    "    for i in range(len(spellCheck_)):\n",
    "        spellCheck_[i] = spell.correction(spellCheck_[i])\n",
    "    \n",
    "    for word in spellCheck_:\n",
    "        if not wordnet.synsets(word):\n",
    "            spellCheck_.remove(word)\n",
    "        \n",
    "    for word in spellCheck_:\n",
    "        flag1 = True\n",
    "        flag2 = True\n",
    "        for i in tokens1:\n",
    "            if word == i:\n",
    "                flag1 = False\n",
    "                break\n",
    "        for i in tokens2:\n",
    "            if word == i:\n",
    "                flag2 = False\n",
    "                break\n",
    "        if flag1 == True and flag2 == True:\n",
    "            spellCheck_.remove(word)\n",
    "    \n",
    "    return spellCheck_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkSimilar(list1, list2):\n",
    "    list1_copy = []\n",
    "    for i in list1:\n",
    "        list1_copy.append(i)\n",
    "    list2_copy = []\n",
    "    for i in list2:\n",
    "        list2_copy.append(i)\n",
    "    \n",
    "    dict1 = dict()\n",
    "    for i in list1:\n",
    "        dict1[i] = 0\n",
    "    for i in list2:\n",
    "        dict1[i] = 0\n",
    "    for i in list1:\n",
    "        dict1[i] = 1 + dict1[i]\n",
    "        \n",
    "    dict2 = dict()\n",
    "    for i in list1:\n",
    "        dict2[i] = 0\n",
    "    for i in list2:\n",
    "        dict2[i] = 0\n",
    "    for i in list2:\n",
    "        dict2[i] = 1 + dict2[i]\n",
    "        \n",
    "    flag = True    \n",
    "    for i in list1:\n",
    "        if dict1[i] != dict2[i]:\n",
    "            flag = False\n",
    "            break\n",
    "            \n",
    "    return flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkSimilarity(S1, S2):\n",
    "    \n",
    "    S1 = S1.lower()\n",
    "    S2 = S2.lower()\n",
    "    \n",
    "    S1 = removeAbbreviations(S1)\n",
    "    S2 = removeAbbreviations(S2)\n",
    "    \n",
    "    S1 = S1[1:len(S1)]\n",
    "    S2 = S2[1:len(S2)]\n",
    "    \n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    words1 = tokenizer.tokenize(S1)\n",
    "    words2 = tokenizer.tokenize(S2)\n",
    "        \n",
    "    spellCheck = []\n",
    "    for i in words1:\n",
    "        flag = True\n",
    "        for j in words2:\n",
    "            if i == j:\n",
    "                flag = False\n",
    "                break\n",
    "        if flag == True:\n",
    "            spellCheck.append(i)\n",
    "    for i in words2:\n",
    "        flag = True\n",
    "        for j in words1:\n",
    "            if i == j:\n",
    "                flag = False\n",
    "                break\n",
    "        if flag == True:\n",
    "            spellCheck.append(i)\n",
    "        \n",
    "    corrected_spellings = spelling(spellCheck, words1, words2)\n",
    "    \n",
    "    for i in corrected_spellings:\n",
    "        if i in spellCheck:\n",
    "            spellCheck.remove(i)\n",
    "    \n",
    "    for i in range(len(corrected_spellings)):\n",
    "        for j in range(len(words1)):\n",
    "            if words1[j] == spellCheck[i]:\n",
    "                words1[j] = corrected_spellings[i]\n",
    "        for j in range(len(words2)):\n",
    "            if words2[j] == spellCheck[i]:\n",
    "                words2[j] = corrected_spellings[i]\n",
    "\n",
    "    porter = PorterStemmer()\n",
    "\n",
    "    lemmatize1 = []\n",
    "    lemmatize2 = []\n",
    "\n",
    "    for word in words1:\n",
    "        lemmatize1.append(porter.stem(word))\n",
    "    for word in words2:\n",
    "        lemmatize2.append(porter.stem(word))\n",
    "        \n",
    "    for i in range(len(lemmatize1)):\n",
    "        words1[i] = lemmatize1[i]\n",
    "    for i in range(len(lemmatize2)):\n",
    "        words2 = lemmatize2\n",
    "    \n",
    "    tokens1 = []\n",
    "    for i in words1:\n",
    "        tokens1.append(i)\n",
    "    tokens2 = []\n",
    "    for i in words2:\n",
    "        tokens2.append(i)\n",
    "    \n",
    "    d = enchant.Dict(\"en_US\")\n",
    "    for word in words1:\n",
    "        if d.check(word) == False:\n",
    "            words1.remove(word)\n",
    "    for word in words2:\n",
    "        if d.check(word) == False:\n",
    "            words2.remove(word)\n",
    "            \n",
    "    technical_terms1 = []\n",
    "    for i in tokens1:\n",
    "        check = False\n",
    "        for j in words1:\n",
    "            if i == j:\n",
    "                check = True\n",
    "                break\n",
    "        if check == False:\n",
    "            technical_terms1.append(i)\n",
    "\n",
    "    technical_terms2 = []\n",
    "    for i in tokens2:\n",
    "        check = False\n",
    "        for j in words2:\n",
    "            if i == j:\n",
    "                check = True\n",
    "                break\n",
    "        if check == False:\n",
    "            technical_terms2.append(i)\n",
    "            \n",
    "    flag = False\n",
    "    flag1 = True\n",
    "\n",
    "    if len(technical_terms1) == len(technical_terms2) and len(technical_terms1) == 0:\n",
    "        None\n",
    "    elif len(technical_terms1) != len(technical_terms2):\n",
    "        flag1 = False\n",
    "    else:\n",
    "        if checkSimilar(technical_terms1, technical_terms2):\n",
    "            flag1 = True     \n",
    "\n",
    "    if flag1 == True:\n",
    "        from nltk.corpus import stopwords\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        stop_words1 = [w for w in words1 if not w in stop_words]\n",
    "        stop_words2 = [w for w in words2 if not w in stop_words]\n",
    "\n",
    "        flag = True\n",
    "        if len(stop_words1) != len(stop_words2):\n",
    "            flag = False\n",
    "        else:\n",
    "            flag = checkSimilar(stop_words1, stop_words2)\n",
    "\n",
    "    return flag\n",
    "\n",
    "# End of Part I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
